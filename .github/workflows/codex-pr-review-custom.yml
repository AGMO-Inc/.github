name: Codex PR Review - Custom (Reusable)

on:
  workflow_call:
    inputs:
      model:
        description: "Model name for review (leave empty to use gpt-5.2-codex)"
        required: false
        type: string
        default: "gpt-5.2-codex"
      max_diff_bytes:
        description: "Limit diff size to avoid huge payloads"
        required: false
        type: number
        default: 180000
    secrets:
      CODEX_API_TOKEN:
        required: true

permissions:
  contents: read
  pull-requests: write
  issues: read

jobs:
  review:
    runs-on: ubuntu-latest

    steps:
      - name: Check out PR merge commit
        uses: actions/checkout@v5
        with:
          ref: refs/pull/${{ github.event.pull_request.number }}/merge

      - name: Fetch PR diff
        id: diff
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          owner="${{ github.repository_owner }}"
          repo="$(echo "${{ github.repository }}" | cut -d/ -f2)"
          pr="${{ github.event.pull_request.number }}"

          curl -sS -L \
            -H "Authorization: Bearer $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3.diff" \
            "https://api.github.com/repos/${owner}/${repo}/pulls/${pr}" \
            > pr.diff

          max="${{ inputs.max_diff_bytes }}"
          size=$(wc -c < pr.diff | tr -d ' ')
          if [ "$size" -gt "$max" ]; then
            head -c "$max" pr.diff > pr.diff.trunc
            mv pr.diff.trunc pr.diff
            echo "truncated=true" >> "$GITHUB_OUTPUT"
          else
            echo "truncated=false" >> "$GITHUB_OUTPUT"
          fi

          echo "diff_path=pr.diff" >> "$GITHUB_OUTPUT"

      - name: Build Codex prompt and schema
        id: prompt
        env:
          GH_TOKEN: ${{ github.token }}
          REPO_FULL: ${{ github.repository }}
          PR_TITLE: ${{ github.event.pull_request.title }}
          PR_AUTHOR: ${{ github.event.pull_request.user.login }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_BODY: ${{ github.event.pull_request.body || '' }}
          DIFF_TRUNCATED: ${{ steps.diff.outputs.truncated }}
        run: |
          set -euo pipefail

          cat > codex_prompt.md <<'EOF'
          You are a senior code reviewer for the project.

          ## Custom/General Review Criteria (5 x 20 = 100)

          Use this rubric for mixed PR types (application code, infrastructure, configuration, docs, CI/CD, scripts).
          If the PR has little/no code, evaluate available artifacts and avoid guessing unseen context.

          ### 1. Security (0-20)
          - No hardcoded secrets, credentials, or sensitive values
          - Input/command/query handling is safe for the changed surface
          - Sensitive information is not exposed in logs, configs, or outputs
          - Access control and permission changes are least-privilege
          - Security trade-offs are explicit and justified

          ### 2. Code Quality (0-20)
          - Changes are clear, readable, and maintainable
          - Naming, structure, and conventions fit the repository style
          - Error handling and edge handling are reasonable
          - No unnecessary complexity, dead code, or risky duplication
          - Documentation/comments are sufficient for non-obvious behavior

          ### 3. Architecture (0-20)
          - Responsibilities are well-separated and cohesion is preserved
          - Dependencies and boundaries remain appropriate
          - Changes align with existing patterns and contracts
          - External integration/configuration changes are scoped correctly
          - Design decisions are consistent with long-term maintainability

          ### 4. Correctness (0-20)
          - Behavior matches intended requirements
          - Backward compatibility and migration impact are handled
          - Config/env-specific behavior is correct
          - Failure modes are considered and handled predictably
          - No obvious functional regressions in changed paths

          ### 5. Performance & Operability (0-20)
          - Performance impact is acceptable for changed flows
          - Resource usage and scalability implications are considered
          - Observability (logs/metrics/alerts) is adequate where needed
          - CI/CD and runtime operability remain stable
          - Rollback/recovery considerations are reasonable when applicable

          ---

          ## OUTPUT FORMAT (MANDATORY)

          You MUST follow this EXACT format.

          ```
          [REVIEW_START]

          [SUMMARY]
          TOTAL: {sum of 5 scores}/100
          VERDICT: {PASS (ðŸŸ¢ O) if total >= 80, FAIL (ðŸ”´ X) if total < 80}
          COMMENT: {1-2 sentence overall assessment}

          [SECURITY]
          SCORE: {number}/20
          ISSUES:
          - {issue description or "None"}
          RECOMMENDATION: {one-line recommendation or "N/A"}

          [CODE_QUALITY]
          SCORE: {number}/20
          ISSUES:
          - {issue description or "None"}
          RECOMMENDATION: {one-line recommendation or "N/A"}

          [ARCHITECTURE]
          SCORE: {number}/20
          ISSUES:
          - {issue description or "None"}
          RECOMMENDATION: {one-line recommendation or "N/A"}

          [CORRECTNESS]
          SCORE: {number}/20
          ISSUES:
          - {issue description or "None"}
          RECOMMENDATION: {one-line recommendation or "N/A"}

          [PERFORMANCE_OPERABILITY]
          SCORE: {number}/20
          ISSUES:
          - {issue description or "None"}
          RECOMMENDATION: {one-line recommendation or "N/A"}

          [REVIEW_END]
          ```

          ### Rules:
          1. Each SCORE MUST be a single integer from 0-20
          2. TOTAL MUST equal the exact sum of the 5 scores
          3. VERDICT MUST be exactly "PASS (ðŸŸ¢ O)" or "FAIL (ðŸ”´ X)" (PASS if TOTAL >= 80, FAIL otherwise)
          4. Every section MUST have at least one ISSUES bullet (use "None" if no issues)
          5. Do NOT add markdown headers (###), bold (**), or any formatting outside this template
          6. The `[REVIEW_START]` and `[REVIEW_END]` tags MUST be present
          7. ISSUES should be concrete and actionable with file paths and line numbers where possible
          8. Use these exact category names: SECURITY, CODE_QUALITY, ARCHITECTURE, CORRECTNESS, PERFORMANCE_OPERABILITY
          EOF

          python - <<'PY'
          import json
          import os
          import urllib.request

          repo_full = os.environ.get("REPO_FULL", "")
          owner, repo = repo_full.split("/", 1)
          pr_number = int(os.environ["PR_NUMBER"])
          token = os.environ.get("GH_TOKEN", "")
          pr_body = (os.environ.get("PR_BODY") or "").strip()
          if not pr_body:
            pr_body = "None"
          elif len(pr_body) > 4000:
            pr_body = pr_body[:4000] + "\n...[truncated]"

          query = """
          query($owner: String!, $repo: String!, $number: Int!) {
            repository(owner: $owner, name: $repo) {
              pullRequest(number: $number) {
                closingIssuesReferences(first: 10) {
                  nodes {
                    number
                    title
                    url
                    state
                    bodyText
                  }
                }
              }
            }
          }
          """

          issue_nodes = []
          issue_lookup_error = ""
          try:
            req_body = json.dumps(
              {
                "query": query,
                "variables": {"owner": owner, "repo": repo, "number": pr_number},
              }
            ).encode("utf-8")
            req = urllib.request.Request(
              "https://api.github.com/graphql",
              data=req_body,
              headers={
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json",
                "Accept": "application/vnd.github+json",
              },
              method="POST",
            )
            with urllib.request.urlopen(req, timeout=20) as resp:
              payload = json.loads(resp.read().decode("utf-8", errors="replace"))
            issue_nodes = (
              payload.get("data", {})
              .get("repository", {})
              .get("pullRequest", {})
              .get("closingIssuesReferences", {})
              .get("nodes", [])
              or []
            )
          except Exception as exc:
            issue_lookup_error = str(exc)

          def one_line(text: str, limit: int) -> str:
            compact = " ".join((text or "").split())
            if not compact:
              return "N/A"
            if len(compact) > limit:
              return compact[:limit] + "..."
            return compact

          with open("pr_context.md", "w", encoding="utf-8") as out:
            out.write("PR body:\n")
            out.write(pr_body + "\n\n")
            out.write("Linked issues:\n")
            if issue_nodes:
              for node in issue_nodes:
                number = node.get("number")
                state = one_line(node.get("state", ""), 30)
                title = one_line(node.get("title", ""), 200)
                url = one_line(node.get("url", ""), 400)
                body = one_line(node.get("bodyText", ""), 240)
                out.write(f"- #{number} [{state}] {title} ({url})\n")
                out.write(f"  Context: {body}\n")
            else:
              if issue_lookup_error:
                out.write(f"- None (lookup failed: {one_line(issue_lookup_error, 160)})\n")
              else:
                out.write("- None\n")
          PY

          {
            echo ""
            echo "---"
            echo "PR number: ${PR_NUMBER}"
            echo "PR title: ${PR_TITLE}"
            echo "PR author: ${PR_AUTHOR}"
            echo "Diff truncated: ${DIFF_TRUNCATED}"
            echo ""
            echo "PR body and linked issues:"
          } >> codex_prompt.md
          cat pr_context.md >> codex_prompt.md
          {
            echo ""
            echo "DIFF:"
          } >> codex_prompt.md
          cat pr.diff >> codex_prompt.md

      - name: Run Codex with selected model
        id: codex_model
        uses: openai/codex-action@v1
        continue-on-error: true
        with:
          openai-api-key: ${{ secrets.CODEX_API_TOKEN }}
          prompt-file: codex_prompt.md
          model: ${{ inputs.model || 'gpt-5.2-codex' }}
          sandbox: read-only
          safety-strategy: drop-sudo
          allow-bots: true

      - name: Run Codex with auto-selected model
        id: codex_auto
        if: ${{ steps.codex_model.outcome != 'success' }}
        uses: openai/codex-action@v1
        continue-on-error: true
        with:
          openai-api-key: ${{ secrets.CODEX_API_TOKEN }}
          prompt-file: codex_prompt.md
          sandbox: read-only
          safety-strategy: drop-sudo
          allow-bots: true

      - name: Prepare review output
        id: call
        env:
          CODEX_FINAL_MESSAGE: ${{ steps.codex_auto.outputs.final-message || steps.codex_model.outputs.final-message }}
          CODEX_OUTCOME: ${{ steps.codex_auto.outcome || steps.codex_model.outcome || 'failure' }}
          CODEX_MODEL_OUTCOME: ${{ steps.codex_model.outcome || 'skipped' }}
          CODEX_AUTO_OUTCOME: ${{ steps.codex_auto.outcome || 'skipped' }}
          REQUESTED_MODEL: ${{ inputs.model || 'gpt-5.2-codex' }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        run: |
          set -euo pipefail

          python - <<'PY'
          import os, re

          raw = os.environ.get("CODEX_FINAL_MESSAGE") or ""
          outcome = os.environ.get("CODEX_OUTCOME") or ""
          model_outcome = os.environ.get("CODEX_MODEL_OUTCOME") or ""
          auto_outcome = os.environ.get("CODEX_AUTO_OUTCOME") or ""
          requested_model = os.environ.get("REQUESTED_MODEL") or ""
          run_url = os.environ.get("RUN_URL") or ""

          def fallback(reason: str) -> str:
            reason = reason.strip().replace("\n", " ")
            return "\n".join([
              "[REVIEW_START]",
              "",
              "[SUMMARY]",
              "TOTAL: 0/100",
              "VERDICT: FAIL (ðŸ”´ X)",
              "COMMENT: Codex review failed to produce a valid report.",
              "",
              "[SECURITY]",
              "SCORE: 0/20",
              "ISSUES:",
              f"- {reason}",
              "RECOMMENDATION: N/A",
              "",
              "[CODE_QUALITY]",
              "SCORE: 0/20",
              "ISSUES:",
              "- None",
              "RECOMMENDATION: N/A",
              "",
              "[ARCHITECTURE]",
              "SCORE: 0/20",
              "ISSUES:",
              "- None",
              "RECOMMENDATION: N/A",
              "",
              "[CORRECTNESS]",
              "SCORE: 0/20",
              "ISSUES:",
              "- None",
              "RECOMMENDATION: N/A",
              "",
              "[PERFORMANCE_OPERABILITY]",
              "SCORE: 0/20",
              "ISSUES:",
              "- None",
              "RECOMMENDATION: N/A",
              "",
              "[REVIEW_END]",
              "",
            ])

          def is_valid_template(s: str) -> tuple[bool, str]:
            if "[REVIEW_START]" not in s or "[REVIEW_END]" not in s:
              return False, "Missing [REVIEW_START]/[REVIEW_END] tags"
            score_re = re.compile(r"^SCORE:\s*(\d{1,2})/20\s*$", re.MULTILINE)
            scores = [int(x) for x in score_re.findall(s)]
            if len(scores) < 5:
              return False, f"Expected 5 SCORE lines, found {len(scores)}"
            scores = scores[:5]
            if any(x < 0 or x > 20 for x in scores):
              return False, "Score out of range"

            m_total = re.search(r"^TOTAL:\s*(\d{1,3})/100\s*$", s, re.MULTILINE)
            if not m_total:
              return False, "Missing TOTAL line"
            total = int(m_total.group(1))
            if total != sum(scores):
              return False, f"TOTAL mismatch (got {total}, expected {sum(scores)})"

            m_verdict = re.search(r"^VERDICT:\s*(PASS|FAIL)\s*\(([^)]+)\)\s*$", s, re.MULTILINE)
            if not m_verdict:
              return False, "Missing VERDICT line"
            verdict = m_verdict.group(1)
            marker = m_verdict.group(2).strip()
            expected = "PASS" if total >= 80 else "FAIL"
            if verdict != expected:
              return False, f"VERDICT mismatch (got {verdict}, expected {expected})"
            expected_marker = "ðŸŸ¢ O" if expected == "PASS" else "ðŸ”´ X"
            if marker != expected_marker:
              return False, f"VERDICT marker mismatch (got {marker}, expected {expected_marker})"

            return True, ""

          if not raw.strip():
            if requested_model:
              reason = f"Codex produced no output. requested_model={requested_model}, model_outcome={model_outcome}, auto_outcome={auto_outcome}, outcome={outcome}. Logs: {run_url}"
            else:
              reason = f"Codex produced no output. auto_outcome={auto_outcome}, outcome={outcome}. Logs: {run_url}"
            out = fallback(reason)
            ok = False
          else:
            valid, why = is_valid_template(raw)
            if not valid:
              out = fallback(f"Codex output invalid: {why}. Logs: {run_url}")
              ok = False
            else:
              out = raw.strip() + "\n"
              ok = True

          open("comment.md", "w", encoding="utf-8").write(out)
          open(os.environ.get("GITHUB_OUTPUT"), "a", encoding="utf-8").write(f"api_ok={'true' if ok else 'false'}\n")
          PY

      - name: Post PR comment
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          owner="${{ github.repository_owner }}"
          repo="$(echo "${{ github.repository }}" | cut -d/ -f2)"
          pr="${{ github.event.pull_request.number }}"

          python - <<'PY' > body.json
          import json
          body = open("comment.md", "r", encoding="utf-8", errors="replace").read()
          print(json.dumps({"body": body}))
          PY

          curl -sS -L \
            -H "Authorization: Bearer $GH_TOKEN" \
            -H "Content-Type: application/json" \
            -d @body.json \
            "https://api.github.com/repos/${owner}/${repo}/issues/${pr}/comments" \
            > /dev/null

      - name: Fail job if Codex failed
        if: ${{ steps.call.outputs.api_ok != 'true' }}
        run: |
          set -euo pipefail
          echo "Codex review failed. See the PR comment and job logs for details." >&2
          exit 1
